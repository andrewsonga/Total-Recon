{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import glob\n",
    "import cv2\n",
    "import liblzfse\n",
    "import configparser\n",
    "\n",
    "dep_scale = 0.2\n",
    "num_skip = 10\n",
    "refcam = \"leftcam\"\n",
    "#seqname_refcam = 'human-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd'\n",
    "seqname_refcam = 'catamelie-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_root(root_dir, cap_frame):\n",
    "    \"\"\"\n",
    "    load all the root se(3)\n",
    "    input is ...-(00000.txt)\n",
    "    \"\"\"\n",
    "    camlist = []\n",
    "    #cam_path = '%s0*.txt'%(root_dir)\n",
    "    cam_path = '%s*.txt'%(root_dir)\n",
    "    all_path = sorted(glob.glob(cam_path))\n",
    "    if cap_frame>0:\n",
    "        all_path = all_path[:cap_frame]\n",
    "    for idx,path in enumerate(all_path):\n",
    "        rtk = np.loadtxt(path)\n",
    "        camlist.append(rtk)\n",
    "    camlist = np.asarray(camlist)\n",
    "    return camlist\n",
    "\n",
    "def read_depth(filepath, height=256, width=192):\n",
    "    with open(filepath, 'rb') as depth_fh:\n",
    "        raw_bytes = depth_fh.read()\n",
    "        decompressed_bytes = liblzfse.decompress(raw_bytes)\n",
    "        depth_img = np.frombuffer(decompressed_bytes, dtype=np.float32)\n",
    "\n",
    "    #depth_img = depth_img.reshape((640, 480))      # For a FaceID camera 3D Video\n",
    "    depth_img = depth_img.copy().reshape((height, width))  # For a LiDAR 3D Video\n",
    "\n",
    "    return depth_img\n",
    "\n",
    "def read_conf(filepath, height=256, width=192):\n",
    "    with open(filepath, 'rb') as conf_fh:\n",
    "        raw_bytes = conf_fh.read()\n",
    "        decompressed_bytes = liblzfse.decompress(raw_bytes)\n",
    "        conf_img = np.frombuffer(decompressed_bytes, dtype=np.uint8)\n",
    "\n",
    "    #conf_img = conf_img.reshape((640, 480))        # For a FaceID camera 3D Video\n",
    "    conf_img = conf_img.copy().reshape((height, width))    # For a LiDAR 3D Video\n",
    "\n",
    "    return conf_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondenceGUI(refcam_image, secondcam_image, refcam_conf, secondcam_conf, alpha = 0.7):\n",
    "    # INPUTS:\n",
    "    # 1. refcam_image:          shape = (H, W, 3)\n",
    "    # 2. secondcam_image:       shape = (H, W, 3)\n",
    "    # 3. refcam_conf:           shape = (H, W)\n",
    "    # 4. secondcam_conf:        shape = (H, W)\n",
    "    #\n",
    "    # RETURNS:\n",
    "    # 1. xy_coords_refcam:     shape = (N, 2)\n",
    "    # 2. xy_coords_secondcam:    shape = (N, 2)\n",
    "\n",
    "    red_image = np.zeros_like(refcam_image)\n",
    "    red_image[:, :, 0] = 255.\n",
    "    refcam_image = refcam_image * (1 - (refcam_conf[..., np.newaxis] < 1.5) * alpha) +  ((refcam_conf[..., np.newaxis] < 1.5) * alpha) * red_image\n",
    "    secondcam_image = secondcam_image * (1 - (secondcam_conf[..., np.newaxis] < 1.5) * alpha) +  ((secondcam_conf[..., np.newaxis] < 1.5) * alpha) * red_image\n",
    "    refcam_image = refcam_image.astype(int)\n",
    "    secondcam_image = secondcam_image.astype(int)\n",
    "    \n",
    "    leftright_image = np.concatenate([refcam_image, secondcam_image], axis = 1)         # shape = (H, 2W, 3)\n",
    "    \n",
    "    f = plt.figure(figsize=(36, 24))\n",
    "    ax = f.add_subplot(111) \n",
    "    ax.imshow(leftright_image)\n",
    "    ax.set_title('Select at least 6 pairs of corresponding points in the refcam and secondcam images')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    xy_coords_refcam = []\n",
    "    xy_coords_secondcam = []\n",
    "\n",
    "    while True:\n",
    "        #plt.sca(ax1)\n",
    "        # one pair\n",
    "        xy_coords = plt.ginput(2, mouse_stop=3, timeout = 0)        # a list of tuples of (x,y) coordinates (mouse_stop = 3 refers to RIGHTCLICK to exit)\n",
    "\n",
    "        # no coordinates returned: exit while loop\n",
    "        if len(xy_coords) == 0:\n",
    "            break\n",
    "        \n",
    "        xy_coords = np.array(xy_coords).astype(int)                 # array.shape = (N = 2, 2)\n",
    "\n",
    "        # check whether the gt depth of the corresponding points of the leftcam / rightcam image has conf. score of 2\n",
    "        xy_coord_refcam = xy_coords[0, ...].copy()\n",
    "        xy_coord_secondcam = xy_coords[1, ...].copy()\n",
    "\n",
    "        xy_coord_secondcam[0] = xy_coord_secondcam[0] - refcam_image.shape[1]\n",
    "        refcam_conf_at_xy = refcam_conf[xy_coord_refcam[1], xy_coord_refcam[0]]\n",
    "        secondcam_conf_at_xy = secondcam_conf[xy_coord_secondcam[1], xy_coord_secondcam[0]]\n",
    "\n",
    "        if refcam_conf_at_xy < 1.5 or secondcam_conf_at_xy < 1.5:\n",
    "            print(\"this point doesn't have a high confidence, choose again\")\n",
    "            continue\n",
    "        else:\n",
    "            ax.plot(xy_coords[:, 0], xy_coords[:, 1], 'r*', markersize=10, linewidth=2)\n",
    "            print(\"choose next pair of corresponding points\")\n",
    "        \n",
    "        xy_coords_refcam.append(xy_coord_refcam)\n",
    "        xy_coords_secondcam.append(xy_coord_secondcam)\n",
    "\n",
    "    plt.close(f)\n",
    "    return xy_coords_refcam, xy_coords_secondcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if refcam == \"leftcam\":\n",
    "    secondcam = \"rightcam\"\n",
    "if refcam == \"rightcam\":\n",
    "    secondcam = \"leftcam\"\n",
    "\n",
    "seqname_secondcam = seqname_refcam.replace(refcam, secondcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract intrinsics for refcam\n",
    "rootdir_bkgd_refcam = \"logdir/{}/obj1/\".format(seqname_refcam)\n",
    "rtks_refcam = load_root(rootdir_bkgd_refcam, 0)  # cap frame=0=>load all\n",
    "ks_refcam = rtks_refcam[0, 3, :]\n",
    "K_refcam = np.array([[ks_refcam[0], 0., ks_refcam[2]],\n",
    "                     [0., ks_refcam[1], ks_refcam[3]],\n",
    "                     [0., 0., 1.]])\n",
    "\n",
    "# extract intrinsics for secondcam\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('configs/%s.config'%seqname_secondcam)\n",
    "ks_secondcam = np.array(config.get('data_0', 'ks').split(\" \")).astype(float)\n",
    "K_secondcam = np.array([[ks_secondcam[0], 0., ks_secondcam[2]],\n",
    "                        [0., ks_secondcam[1], ks_secondcam[3]],\n",
    "                        [0., 0., 1.]])\n",
    "\n",
    "gt_imgpath_secondcam = config.get('data_0', 'datapath1')\n",
    "gt_imgpath_refcam = gt_imgpath_secondcam.replace(secondcam, refcam)\n",
    "\n",
    "gt_conf_secondcam = gt_imgpath_secondcam.replace(\"JPEGImages\", \"ConfidenceMaps\")\n",
    "gt_conf_refcam = gt_imgpath_refcam.replace(\"JPEGImages\", \"ConfidenceMaps\")\n",
    "\n",
    "gt_imglist_secondcam = sorted(glob.glob(os.path.join(gt_imgpath_secondcam, \"*.jpg\")))\n",
    "gt_imglist_refcam = sorted(glob.glob(os.path.join(gt_imgpath_refcam, \"*.jpg\")))\n",
    "\n",
    "gt_conflist_secondcam = sorted(glob.glob(os.path.join(gt_conf_secondcam, \"*.conf\")))\n",
    "gt_conflist_refcam = sorted(glob.glob(os.path.join(gt_conf_refcam, \"*.conf\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "num_corresp = 0\n",
    "rvecs = []\n",
    "tvecs = []\n",
    "\n",
    "P_refcams = []\n",
    "P_secondcams = []\n",
    "p_refcams = []\n",
    "p_secondcams = []\n",
    "\n",
    "for (gt_imgpath_refcam, gt_imgpath_secondcam) in zip(gt_imglist_refcam, gt_imglist_secondcam):\n",
    "    print(\"counter = {}\".format(counter))\n",
    "    if counter % num_skip == 0:\n",
    "\n",
    "        refcam_image = cv2.imread(gt_imgpath_refcam)[:,:,::-1]\n",
    "        secondcam_image = cv2.imread(gt_imgpath_secondcam)[:,:,::-1]\n",
    "\n",
    "        gt_confpath_refcam = gt_imgpath_refcam.replace(\"JPEGImages\", \"ConfidenceMaps\").replace(\".jpg\", \".conf\")\n",
    "        gt_confpath_secondcam = gt_imgpath_secondcam.replace(\"JPEGImages\", \"ConfidenceMaps\").replace(\".jpg\", \".conf\")\n",
    "        gt_deppath_refcam = gt_imgpath_refcam.replace(\"JPEGImages\", \"DepthMaps\").replace(\".jpg\", \".depth\")\n",
    "        gt_deppath_secondcam = gt_imgpath_secondcam.replace(\"JPEGImages\", \"DepthMaps\").replace(\".jpg\", \".depth\")\n",
    "        \n",
    "        refcam_conf = read_conf(gt_confpath_refcam)\n",
    "        secondcam_conf = read_conf(gt_confpath_secondcam)\n",
    "        \n",
    "        refcam_depth = read_depth(gt_deppath_refcam)\n",
    "        #refcam_depth_rnd = glob.glob(\"logdir/{}/nvs-inputview-dph_%05d.png\".format(seqname_refcam)\n",
    "        secondcam_depth = read_depth(gt_deppath_secondcam)\n",
    "\n",
    "        refcam_conf[np.isnan(refcam_depth)] = 0.\n",
    "        refcam_depth[np.isnan(refcam_depth)] = 4.\n",
    "        ################## ignoring pixels whose depth values are close to camera ############\n",
    "        refcam_conf[refcam_depth > 2.0] = 0.\n",
    "        ######################################################################################\n",
    "        refcam_depth = refcam_depth * dep_scale\n",
    "\n",
    "        secondcam_conf[np.isnan(secondcam_depth)] = 0.\n",
    "        secondcam_depth[np.isnan(secondcam_depth)] = 4.\n",
    "        ################## ignoring pixels whose depth values are close to camera ############\n",
    "        secondcam_conf[secondcam_depth > 2.0] = 0.\n",
    "        ######################################################################################\n",
    "        secondcam_depth = secondcam_depth * dep_scale\n",
    "\n",
    "        refcam_conf = cv2.resize(refcam_conf, refcam_image.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "        secondcam_conf = cv2.resize(secondcam_conf, secondcam_image.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "        refcam_depth = cv2.resize(refcam_depth, refcam_image.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "        secondcam_depth = cv2.resize(secondcam_depth, secondcam_image.shape[:2][::-1], interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # 1. manually annotate correspondences (at least 6)\n",
    "        xy_coords_refcam, xy_coords_secondcam = correspondenceGUI(refcam_image, secondcam_image, refcam_conf, secondcam_conf)\n",
    "        \n",
    "        if len(xy_coords_refcam) == 0 and len(xy_coords_secondcam) == 0:\n",
    "            counter += 1\n",
    "            continue\n",
    "        \n",
    "        xy_coords_refcam = np.stack(xy_coords_refcam, axis = 0)\n",
    "        xy_coords_secondcam = np.stack(xy_coords_secondcam, axis = 0)\n",
    "\n",
    "        # 2. compute relative transformation between leftcam and rightcam\n",
    "        p_refcam = xy_coords_refcam\n",
    "        p_secondcam = xy_coords_secondcam\n",
    "        \n",
    "        x_coord_refcam = xy_coords_refcam[:, 0]\n",
    "        y_coord_refcam = xy_coords_refcam[:, 1] \n",
    "        p_homo_refcam = np.stack([x_coord_refcam, y_coord_refcam, np.ones_like(x_coord_refcam)], axis=-1)                                       # shape = (N, 3)\n",
    "        depth_refcam = refcam_depth[y_coord_refcam, x_coord_refcam]                                                                             # shape = (N)\n",
    "\n",
    "        x_coord_secondcam = xy_coords_secondcam[:, 0]\n",
    "        y_coord_secondcam = xy_coords_secondcam[:, 1] \n",
    "        p_homo_secondcam = np.stack([x_coord_secondcam, y_coord_secondcam, np.ones_like(x_coord_secondcam)], axis=-1)                           # shape = (N, 3)\n",
    "        depth_secondcam = secondcam_depth[y_coord_secondcam, x_coord_secondcam]                                                                 # shape = (N)\n",
    "        \n",
    "        P_refcam = np.repeat(depth_refcam[:, np.newaxis], 3, axis = -1) * np.matmul(p_homo_refcam, np.linalg.inv(K_refcam.T))                   # shape = (N, 3)\n",
    "        P_secondcam = np.repeat(depth_secondcam[:, np.newaxis], 3, axis = -1) * np.matmul(p_homo_secondcam, np.linalg.inv(K_secondcam.T))       # shape = (N, 3)\n",
    "\n",
    "        p_refcams.append(p_refcam)\n",
    "        p_secondcams.append(p_secondcam)\n",
    "\n",
    "        P_refcams.append(P_refcam)\n",
    "        P_secondcams.append(P_secondcam)\n",
    "\n",
    "        num_corresp += P_secondcam.shape[0]\n",
    "\n",
    "        '''\n",
    "        _, rvec_init, tvec_init = cv2.solvePnP(P_secondcam[..., np.newaxis].astype('float'), \n",
    "                                               p_refcam[..., np.newaxis].astype('float'), \n",
    "                                               K_refcam, \n",
    "                                               0,\n",
    "                                               flags=cv2.SOLVEPNP_DLS)\n",
    "\n",
    "        _, rvec_finetuned, tvec_finetuned = cv2.solvePnP(P_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                        p_refcam[..., np.newaxis].astype('float'),\n",
    "                                                        K_refcam,\n",
    "                                                        0,\n",
    "                                                        rvec_init,\n",
    "                                                        tvec_init,\n",
    "                                                        useExtrinsicGuess=True,\n",
    "                                                        flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "        \n",
    "        # compute reprojection error\n",
    "        reprojected_p_refcam, _, = cv2.projectPoints(P_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                     rvec_finetuned,\n",
    "                                                     tvec_finetuned,\n",
    "                                                     K_refcam,\n",
    "                                                     0)\n",
    "                \n",
    "        reprojected_p_refcam = reprojected_p_refcam[:, 0, :]                                    # reprojected_p_refcam.shape = (N, 1, 2)\n",
    "        reproj_err = np.mean(np.linalg.norm(reprojected_p_refcam - p_refcam, axis = -1))\n",
    "        #reproj_err = np.mean(np.linalg.norm(reprojected_p_refcam - p_normrefcam, axis = -1))\n",
    "        print(\"averaged reprojection error [units: pixels]: {}\".format(reproj_err))\n",
    "        '''\n",
    "\n",
    "        #rvecs.append(rvec_finetuned)\n",
    "        #tvecs.append(tvec_finetuned)\n",
    "\n",
    "    #if counter // num_skip == 4:\n",
    "    #    break\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "    if num_corresp > 30:\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "rvec = np.mean(np.stack(rvecs, axis = 0), axis = 0)\n",
    "tvec = np.mean(np.stack(tvecs, axis = 0), axis = 0)\n",
    "\n",
    "secondcam2refcam_rot = cv2.Rodrigues(rvec)[0]\n",
    "secondcam2refcam = np.eye(4)\n",
    "secondcam2refcam[:3, :3] = secondcam2refcam_rot                                     # shape = (3, 3)\n",
    "secondcam2refcam[:3, 3:4] = tvec                                                    # shape = (3, 1)\n",
    "refcam2secondcam = np.linalg.inv(secondcam2refcam)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_refcam = np.concatenate(p_refcams, axis=0)\n",
    "p_secondcam = np.concatenate(p_secondcams, axis=0)\n",
    "\n",
    "P_refcam = np.concatenate(P_refcams, axis=0)\n",
    "P_secondcam = np.concatenate(P_secondcams, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (version 1) USING ALL POINTS FOR SOLVING refcam2second directly\n",
    "\n",
    "# compute relative transformation between rightcam and leftcam\n",
    "_, rvec_init, tvec_init = cv2.solvePnP(P_refcam[..., np.newaxis].astype('float'), \n",
    "                                        p_secondcam[..., np.newaxis].astype('float'), \n",
    "                                        K_secondcam, \n",
    "                                        0,\n",
    "                                        flags=cv2.SOLVEPNP_DLS)\n",
    "\n",
    "_, rvec_finetuned, tvec_finetuned = cv2.solvePnP(P_refcam[..., np.newaxis].astype('float'),\n",
    "                                                p_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                K_secondcam,\n",
    "                                                0,\n",
    "                                                rvec_init,\n",
    "                                                tvec_init,\n",
    "                                                useExtrinsicGuess=True,\n",
    "                                                flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "# compute reprojection error\n",
    "reprojected_p_refcam, _, = cv2.projectPoints(P_refcam[..., np.newaxis].astype('float'),\n",
    "                                                rvec_finetuned,\n",
    "                                                tvec_finetuned,\n",
    "                                                K_secondcam,\n",
    "                                                0)\n",
    "        \n",
    "reprojected_p_refcam = reprojected_p_refcam[:, 0, :]        # reprojected_p_refcam.shape = (N, 1, 2)\n",
    "reproj_err = np.mean(np.linalg.norm(reprojected_p_refcam - p_secondcam, axis = -1))\n",
    "print(\"averaged reprojection error [units: pixels]: {}\".format(reproj_err))\n",
    "\n",
    "refcam2secondcam_rot = cv2.Rodrigues(rvec_finetuned)[0]\n",
    "refcam2secondcam = np.eye(4)\n",
    "refcam2secondcam[:3, :3] = refcam2secondcam_rot                                             # shape = (3, 3)\n",
    "refcam2secondcam[:3, 3:4] = tvec_finetuned                                                  # shape = (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (version 2) USING ALL POINTS FOR SOLVING second2refcam first and then getting refcam2secondcam\n",
    "\n",
    "# normalize p_refcam and K_refcam\n",
    "centroid = np.mean(p_refcam, axis = 0, keepdims=True)\n",
    "scale = np.sqrt(2) / np.mean(np.linalg.norm(p_refcam - centroid, axis = -1))\n",
    "scaled_centroid = centroid * scale\n",
    "shift = -scaled_centroid\n",
    "K_refcam2norm = np.array([[scale, 0,        shift[0, 0]],\n",
    "                            [0,     scale,    shift[0, 1]],\n",
    "                            [0,     0,        1]])\n",
    "x_coord_refcam = p_refcam[:, 0]\n",
    "y_coord_refcam = p_refcam[:, 1]\n",
    "p_homo_refcam = np.stack([x_coord_refcam, y_coord_refcam, np.ones_like(x_coord_refcam)], axis=-1)                                       # shape = (N, 3)\n",
    "p_homo_normrefcam = np.matmul(p_homo_refcam, K_refcam2norm.T)                                                                           # shape = (N, 3)\n",
    "p_normrefcam = p_homo_normrefcam[:, :2]\n",
    "K_normrefcam = np.matmul(K_refcam2norm, K_refcam)                                                                                       # shape = (3, 3)\n",
    "\n",
    "\"\"\"\n",
    "# compute relative transformation between leftcam and rightcam\n",
    "_, rvec_init, tvec_init = cv2.solvePnP(P_secondcam[..., np.newaxis].astype('float'), \n",
    "                                        p_normrefcam[..., np.newaxis].astype('float'), \n",
    "                                        K_normrefcam, \n",
    "                                        0,\n",
    "                                        flags=cv2.SOLVEPNP_DLS)\n",
    "\n",
    "_, rvec_finetuned, tvec_finetuned = cv2.solvePnP(P_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                p_normrefcam[..., np.newaxis].astype('float'),\n",
    "                                                K_normrefcam,\n",
    "                                                0,\n",
    "                                                rvec_init,\n",
    "                                                tvec_init,\n",
    "                                                useExtrinsicGuess=True,\n",
    "                                                flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\"\"\"\n",
    "\n",
    "# cv2.solvePnPRansac -> retval, rvec, tvec, inliers\n",
    "_, rvec_init, tvec_init, _ = cv2.solvePnPRansac(P_secondcam[..., np.newaxis].astype('float'), \n",
    "                                        p_normrefcam[..., np.newaxis].astype('float'), \n",
    "                                        K_normrefcam, \n",
    "                                        0,\n",
    "                                        reprojectionError = 0.02,\n",
    "                                        flags=cv2.SOLVEPNP_DLS)\n",
    "\n",
    "# cv2.solvePnPRansac -> retval, rvec, tvec, inliers\n",
    "_, rvec_finetuned, tvec_finetuned, _ = cv2.solvePnPRansac(P_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                p_normrefcam[..., np.newaxis].astype('float'),\n",
    "                                                K_normrefcam,\n",
    "                                                0,\n",
    "                                                rvec_init,\n",
    "                                                tvec_init,\n",
    "                                                useExtrinsicGuess=True,\n",
    "                                                reprojectionError = 0.02,\n",
    "                                                flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "# compute reprojection error\n",
    "reprojected_p_refcam, _, = cv2.projectPoints(P_secondcam[..., np.newaxis].astype('float'),\n",
    "                                                rvec_finetuned,\n",
    "                                                tvec_finetuned,\n",
    "                                                K_normrefcam,\n",
    "                                                0)\n",
    "                                                #K_refcam,\n",
    "                                                #0)\n",
    "        \n",
    "reprojected_p_refcam = reprojected_p_refcam[:, 0, :]        # reprojected_p_refcam.shape = (N, 1, 2)\n",
    "#reproj_err = np.mean(np.linalg.norm(reprojected_p_refcam - p_refcam, axis = -1))\n",
    "reproj_err = np.mean(np.linalg.norm(reprojected_p_refcam - p_normrefcam, axis = -1))\n",
    "print(\"averaged reprojection error [units: pixels]: {}\".format(reproj_err))\n",
    "\n",
    "secondcam2refcam_rot = cv2.Rodrigues(rvec_finetuned)[0]\n",
    "secondcam2refcam = np.eye(4)\n",
    "secondcam2refcam[:3, :3] = secondcam2refcam_rot                                             # shape = (3, 3)\n",
    "secondcam2refcam[:3, 3:4] = tvec_finetuned                                                  # shape = (3, 1)\n",
    "refcam2secondcam = np.linalg.inv(secondcam2refcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refcam2secondcam)\n",
    "np.save(\"/data2/ndsong/normrefcam2secondcam.npy\", refcam2secondcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averaged reprojection error [units: pixels]: 0.031017746431295713\n",
    "#averaged reprojection error [units: pixels]: 0.030368957641923437"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('banmo-cu113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac9a21516e7d33d755adb2f62e062d2ae163e9208ff05afee44babf7dd79d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
