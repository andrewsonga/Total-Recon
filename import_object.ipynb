{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\" #opengl seems to only work with TPU\n",
    "import pyrender\n",
    "from pyrender import IntrinsicsCamera,Mesh, Node, Scene,OffscreenRenderer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load asset\n",
    "resolver = trimesh.resolvers.FilePathResolver('mesh_material/UnicornHorn_OBJ/')\n",
    "asset_mesh = trimesh.load(file_obj='mesh_material/UnicornHorn_OBJ/UnicornHorn.obj', resolver = resolver, process=False)\n",
    "\n",
    "#mesh.vertices[:, 2] = mesh.vertices[:, 2] + 100.\n",
    "\n",
    "color = asset_mesh.visual.to_color()\n",
    "asset_mesh.visual.vertex_colors = color\n",
    "img_size = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 255]\n",
      " [255 255 255 255]\n",
      " [255 255 255 255]\n",
      " ...\n",
      " [255 255 255 255]\n",
      " [255 255 255 255]\n",
      " [255 255 255 255]]\n",
      "color: <trimesh.visual.color.ColorVisuals object at 0x7f5483bbd7f0>\n"
     ]
    }
   ],
   "source": [
    "print(asset_mesh.visual.vertex_colors.vertex_colors)\n",
    "print(\"color: {}\".format(color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. load deformed fg mesh\n",
    "#fg_mesh = trimesh.load('logdir/catamelie-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd/obj0/catamelie-dualrig002-fgbg-leftcam-mesh-00000.obj', process=False)\n",
    "fg_mesh = trimesh.load('logdir/human-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd/obj0/human-dualrig-fgbg002-leftcam-mesh-00000.obj', process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of faces: (620776, 3)\n",
      "number of vertices: (310236, 3)\n",
      "number of face normals: (620776, 3)\n",
      "number of vertex normals: (310236, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of faces: {}\".format(fg_mesh.faces.shape))\n",
    "print(\"number of vertices: {}\".format(fg_mesh.vertices.shape))\n",
    "print(\"number of face normals: {}\".format(fg_mesh.face_normals.shape))\n",
    "print(\"number of vertex normals: {}\".format(fg_mesh.vertex_normals.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_mesh.vertices[chosen_vertex, :]: [-0.01416462  0.12319944  0.02791327]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# 3. align (and scale) the 3d asset to the fg mesh\n",
    "####################################################\n",
    "\n",
    "# 3a. scale vertices of 3d asset\n",
    "scale = 0.0005\n",
    "asset_mesh.vertices = asset_mesh.vertices * scale\n",
    "\n",
    "# 3b. transform vertices of 3d asset to fg frame using \"asset2fg\" transformation \n",
    "# \n",
    "#chosen_vertex = 55\n",
    "chosen_vertex = 5831\n",
    "asset2fg = np.eye(4)\n",
    "\n",
    "# translation component = coordinate of the designated vertex in the fgframe\n",
    "asset2fg[:3, 3] = fg_mesh.vertices[chosen_vertex, :].copy()\n",
    "print(\"fg_mesh.vertices[chosen_vertex, :]: {}\".format(fg_mesh.vertices[chosen_vertex, :]))\n",
    "\n",
    "# rotation component:\n",
    "# 2nd column: normal = fg_mesh.vertex_normal[chosen_vertex, :]\n",
    "asset2fg[:3, 1] = fg_mesh.vertex_normals[chosen_vertex, :].copy()           # unit length normal vector\n",
    "\n",
    "# 1st column: [-R_32, 0, R_12].T where 2nd column = [R_12, R_22, R_23].T\n",
    "asset2fg[0, 0] = -asset2fg[2, 1]\n",
    "asset2fg[1, 0] = 0.\n",
    "asset2fg[2, 0] = asset2fg[0, 1]\n",
    "\n",
    "\n",
    "asset_vertices_assetframe_homo = np.concatenate([asset_mesh.vertices, np.ones_like(asset_mesh.vertices[:, 0:1])], axis = -1)        # (N, 3) + (N, 1) = (N, 4)\n",
    "asset_vertices_fgframe_homo = np.matmul(asset2fg, asset_vertices_assetframe_homo.T).T                                               # (4, N) = (4, 4) * (4, N) -> (N, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4a. load extrinsics (world2cam transformations)\n",
    "#fg2cam = np.loadtxt('logdir/catamelie-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd/obj0/catamelie-dualrig002-fgbg-leftcam-cam-00000.txt')\n",
    "fg2cam = np.loadtxt('logdir/human-dualrig002-properlyscaledcams-leftcam-ds-finetune-fgbkgd/obj0/human-dualrig-fgbg002-leftcam-cam-00000.txt')\n",
    "fg2cam[3, :] = np.array([0., 0., 0., 1.])\n",
    "\n",
    "fg_vertices_fgframe_homo = np.concatenate([fg_mesh.vertices, np.ones_like(fg_mesh.vertices[:, 0:1])], axis = -1)                             # (N, 3) + (N, 1) = (N, 4)\n",
    "fg_vertices_camframe_homo = np.matmul(fg2cam, fg_vertices_fgframe_homo.T).T                                                                  # (4, N) = (4, 4) * (4, N) -> (N, 4)\n",
    "\n",
    "asset_vertices_camframe_homo = np.matmul(fg2cam, asset_vertices_fgframe_homo.T).T\n",
    "\n",
    "asset_mesh.vertices = asset_vertices_camframe_homo[:, :3]               # (N, 3)\n",
    "fg_mesh.vertices = fg_vertices_camframe_homo[:, :3]                     # (N, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. insert all meshes into the scene\n",
    "r = OffscreenRenderer(img_size, img_size)\n",
    "scene = Scene(ambient_light=0.4*np.asarray([1.,1.,1.,1.]))\n",
    "\n",
    "asset_meshr = Mesh.from_trimesh(asset_mesh, smooth=True)\n",
    "fg_meshr = Mesh.from_trimesh(fg_mesh, smooth=True)\n",
    "\n",
    "scene.add_node(Node(mesh=asset_meshr))\n",
    "scene.add_node(Node(mesh=fg_meshr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. add camera to the scene\n",
    "\n",
    "cam_time = IntrinsicsCamera(\n",
    "            800,\n",
    "            800,\n",
    "            360,\n",
    "            480,\n",
    "            znear=1e-3,zfar=1000)\n",
    "cam_pose = -np.eye(4); cam_pose[0,0]=1; cam_pose[-1,-1]=1\n",
    "cam_node = scene.add(cam_time, pose=cam_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. add a light source to the scene\n",
    "theta = 9*np.pi/9\n",
    "init_light_pose = np.asarray([[1,0,0,0],[0,np.cos(theta),-np.sin(theta),0],[0,np.sin(theta),np.cos(theta),0],[0,0,0,1]])\n",
    "light_pose = init_light_pose\n",
    "direc_l = pyrender.DirectionalLight(color=np.ones(3), intensity=6.0)\n",
    "direc_l_node = scene.add(direc_l, pose=light_pose)\n",
    "\n",
    "# 8. render Scene\n",
    "mesh_rnd_color, mesh_rnd_depth = r.render(scene,flags=pyrender.RenderFlags.SHADOWS_DIRECTIONAL | pyrender.RenderFlags.SKIP_CULL_FACES)\n",
    "r.delete()\n",
    "\n",
    "#mesh_rnd_color = mesh_rnd_color[:960, :720, :3]\n",
    "cv2.imwrite('mesh_material/UnicornHorn_OBJ/rendered_mesh.png', mesh_rnd_color[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_rnd_depth: [0.31481358 0.31471983 0.314602   ... 0.2590786  0.2590376  0.25937387]\n",
      "mesh_rnd_color: [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"mesh_rnd_depth: {}\".format(mesh_rnd_depth[mesh_rnd_depth > 0]))\n",
    "print(\"mesh_rnd_color: {}\".format(mesh_rnd_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('banmo-cu113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a9323ed9d4641cab6db91fe15920a6c329a06c2de06e4fe6c3a5780b989632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
